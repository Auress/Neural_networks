{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Урок 1. Основы обучения нейронных сетей#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -- Автор: Шенк Евгений Станиславович"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Попробуйте видоизменить параметры разобранной на уроке двухслойной нейронной сети таким образом, чтобы улучшить ее точность. Проведите анализ — что приводит к ухудшению точности нейронной сети? Что приводит к увеличению ее точности?</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изначальные параметры:\n",
    "\n",
    "Скорость обучения (n) = 0.1,  \n",
    "колическтво итераций (iter) = 100000 (=100k),   \n",
    "количество выходов 1-слоя = кол-во входов 2-слоя = 5,  \n",
    "функция активации - сигмоида.  \n",
    "Random state = 2177.  \n",
    "\n",
    "При таких данных результат 97.04%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменение количества итераций не влияет при данных условиях на качество модели, т.е. можно сократить со 100000 до 50000, а качество упадет с 97.04% до 97.01%, а модель работать будет быстрее. При еще большем снижении кол-ва итераций качество ухудшается, т.к. модель недообучается.\n",
    "\n",
    "Увеличение скорости обучения может приводить к пропуску минимума и некорректным результатам, а уменьшение требует большего количества итераций (для 100к итераций можно взять скорость обучения n=0.01). Хотя в нашем случае точность выросла (При n=0.3 iter=200k результат получился 98.22%).\n",
    "\n",
    "Изменение функции активации приводило в основном к падению точности:\n",
    "для сравнения получилось:  \n",
    "n=0.005,  (при значениях n>0.1 - tanh(x) и Leaky ReLU вообще выдавали некорректные значения)  \n",
    "iter=200000,  \n",
    "сигмоида - 97.04% (как и у изначальных значений)  \n",
    "\n",
    "tanh(x) - 96.29%  \n",
    "- Функция: np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x)   \n",
    "- Производная: (2 / (np.exp(x) + np.exp(-x)))**2 \n",
    "\n",
    "Leaky ReLU - 94.39%  \n",
    "- Функция: np.maximum(0.01*x, x)  \n",
    "- Производная: np.maximum(0.01*(x<0), (x>=0))  \n",
    "\n",
    "Изменение количества выходов 1-слоя и кол-во входов 2-слоя (при n=0.005, iter=200000) с 5 на:  \n",
    "- 3 - 95.82%  \n",
    "- 7 - 97.04%  \n",
    "- 10 -  97.06%  \n",
    "\n",
    "Увеличение не приводит к заметному улучшению модели, а уменьшение ухудшает качество модели.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
